{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer, PowerTransformer, StandardScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import cohen_kappa_score, matthews_corrcoef, balanced_accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task\n",
    "I have to create some kid of algorith that allows us to determine if given website contains information about 'cancer tumorbaord'. In my opinion the best solution would be to create NLP ML model. I see this as a 3 step task.\n",
    "\n",
    "* Extract insightful info from various german websites\n",
    "* Transform raw text to some form of data that could be used to train ML models\n",
    "* Train, score and tune the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data cleaning\n",
    "### In order to train model, we have to remove unessecary text and there is a lot of it\n",
    "My assumption is that most important information about article will be inside tags: `container, p, article`. So in my approach I will extract text mostly from those tags. Of course some information will be lost in the process, but this step could be optimized in the future without the need of changing the next steps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "Usage is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_text(url, tags):\n",
    "    \"\"\"This function removes all tags provided\"\"\"\n",
    "        \n",
    "    try:\n",
    "        with open(url, \"r\", encoding='utf-8') as file:\n",
    "            site_raw = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        ## Website has different encoding try old german format\n",
    "        with open(url, \"r\", encoding='ISO-8859-1') as file:\n",
    "            site_raw = file.read()\n",
    "        \n",
    "    site = BeautifulSoup(site_raw)\n",
    "    \n",
    "    for tag in tags:\n",
    "        for section in site.find_all(tag):\n",
    "            section.decompose()\n",
    "            \n",
    "    return site.text\n",
    "\n",
    "def clean_site_text(site_text):\n",
    "    \"\"\"Cleans website text form meaningless symbols\"\"\"\n",
    "    clean_text = re.sub(\"\\\\n\",\"\",site_text)\n",
    "    clean_text = re.sub(\"\\\\t\",\"\",clean_text)\n",
    "    clean_text = re.sub(\"[0-9]+\",\"\",clean_text)\n",
    "    clean_text = re.sub(\" - \",\"\",clean_text)\n",
    "    clean_text = re.sub(\"( -|\\+|/|\\(|\\))\",\"\",clean_text)\n",
    "    clean_text = re.sub(\"(!|\\?|\\.|,)\",\"\",clean_text)\n",
    "    clean_text = re.sub(\" ([a-z]|[A-Z]) \",\"\",clean_text)\n",
    "    clean_text = re.sub(\"\\s+\",\" \",clean_text)\n",
    "        \n",
    "    return clean_text\n",
    "\n",
    "def text_to_list(text):\n",
    "    \"\"\"Creates list of words from one string containing different words seperated by whitespace\"\"\"\n",
    "    word_list = list(text.split(\" \"))\n",
    "    for i in range(len(word_list)):\n",
    "        word_list[i] = word_list[i].lower()\n",
    "        \n",
    "    return word_list\n",
    "\n",
    "def list_to_counted_dict(word_list):\n",
    "    \"\"\"Creates dictionary of words from a 'word_list' with values being the number of their occurances in 'word_list'\"\"\"\n",
    "    \n",
    "    ## ' -all' is unique key that for sure does not exist in word_list\n",
    "    words={\" -all\": len(word_list)}\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in words:\n",
    "            words[word]+=1\n",
    "        else:\n",
    "            words[word]=1\n",
    "            \n",
    "    return words\n",
    "\n",
    "def create_row(doc_id, word_dict, keyword_list):\n",
    "    \"\"\"This function creates dataframe row with information about keyword occurances in text provided from website of given 'doc_id'\"\"\"\n",
    "    \n",
    "    occurances_dict = dict.fromkeys(keyword_list, [0])\n",
    "    occurances_dict['doc_id'] = [doc_id]\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        if keyword in word_dict:\n",
    "            occurances_dict[keyword]=[round(word_dict[keyword]/word_dict[' -all'],6)]\n",
    "    \n",
    "    return pd.DataFrame.from_dict(occurances_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords\n",
    "I want ot check for every website which keywords are used on it and how often.\n",
    "The idea is that this would give enough information for model, to predict accurately not only if website contains information about tumorbaord, but even the tumor type. \n",
    "\n",
    "For this I will use prebuild dataset, maching specific words in german to tumor type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "_keywords = pd.read_csv(\"keyword2tumor_type.csv\")\n",
    "keywords = list(_keywords['keyword'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of getting information from website\n",
    "**From every website with given 'doc_id' I will extract content, but additionally make sure that is does not contain text from unimportant tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDie operative Therapie der BauchspeicheldrÃ¼se beziehungsweise ihrer VerÃ¤nderungen ist ei'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = 0\n",
    "\n",
    "url = f'htmls/{doc_id}.html'\n",
    "unimportant_tags = ['head','header','script', 'nav', 'footer']\n",
    "\n",
    "\n",
    "site_text = get_site_text(url, tags)\n",
    "site_text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then I will remove all meaningless characters from it i.e. '\\n', ' - '**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die operative Therapie der BauchspeicheldrÃ¼se beziehungsweise ihrer VerÃ¤nderungen ist ein besonder'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = clean_site_text(site_text)\n",
    "clean_text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then I transform this one big string into list of words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['die', 'operative', 'therapie', 'der']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = text_to_list(clean_text)\n",
    "word_list[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But I want to know how many times they are used on single website, so I count it and make a dict of it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict=list_to_counted_dict(word_list)\n",
    "word_dict['radioonkologen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The last step is to see if any words are from the keyword list and if so, I want to save that information and put it in a row describing this website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senologische</th>\n",
       "      <th>brustzentrum</th>\n",
       "      <th>breast</th>\n",
       "      <th>thorax</th>\n",
       "      <th>thorakale</th>\n",
       "      <th>brustkonferenz</th>\n",
       "      <th>rektum</th>\n",
       "      <th>colorec</th>\n",
       "      <th>viszeralchirurgie</th>\n",
       "      <th>visceralonkologischem</th>\n",
       "      <th>...</th>\n",
       "      <th>oral</th>\n",
       "      <th>prätherapeutische</th>\n",
       "      <th>tumore im kindesalter</th>\n",
       "      <th>kinderonkologisches</th>\n",
       "      <th>kinderonkologie</th>\n",
       "      <th>pädiatrische</th>\n",
       "      <th>schwerpunkt</th>\n",
       "      <th>stammzelltransplantation</th>\n",
       "      <th>chirurgisch</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   senologische  brustzentrum  breast  thorax  thorakale  brustkonferenz  \\\n",
       "0             0             0       0       0          0               0   \n",
       "\n",
       "   rektum  colorec  viszeralchirurgie  visceralonkologischem  ...  oral  \\\n",
       "0       0        0                  1                      0  ...     0   \n",
       "\n",
       "   prätherapeutische  tumore im kindesalter  kinderonkologisches  \\\n",
       "0                  0                      0                    0   \n",
       "\n",
       "   kinderonkologie  pädiatrische  schwerpunkt  stammzelltransplantation  \\\n",
       "0                0             0            1                         0   \n",
       "\n",
       "   chirurgisch  doc_id  \n",
       "0            0       0  \n",
       "\n",
       "[1 rows x 127 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row = create_row(doc_id, word_dict, keywords)\n",
    "data_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "Function below does it all for every website with `doc_id` inside `id_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(id_list):\n",
    "    \"\"\"This function should be used for creating both train and test dataset\"\"\"\n",
    "    \n",
    "    unimportant_tags = ['head','header','script', 'nav', 'footer']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "        \n",
    "    for doc_id in id_list:\n",
    "\n",
    "        url = f'htmls/{doc_id}.html'\n",
    "        site_text = get_site_text(url, unimportant_tags)\n",
    "        clean_text = clean_site_text(site_text)\n",
    "        word_list = text_to_list(clean_text)\n",
    "        word_dict=list_to_counted_dict(word_list)\n",
    "        data_row = create_row(doc_id, word_dict, keywords)\n",
    "        \n",
    "        df = df.append(data_row)\n",
    "        \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instructions = pd.read_csv(\"train.csv\")\n",
    "train_id_list = list(train_instructions['doc_id'])\n",
    "y = list(train_instructions['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a small peak at the 'train_instructions' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://elbe-elster-klinikum.de/fachbereiche/ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://klinikum-bayreuth.de/einrichtungen/zent...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://klinikum-braunschweig.de/info.php/?id_o...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://klinikum-braunschweig.de/info.php/?id_o...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://klinikum-braunschweig.de/zuweiser/tumor...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  doc_id  label\n",
       "0  http://elbe-elster-klinikum.de/fachbereiche/ch...       1      1\n",
       "1  http://klinikum-bayreuth.de/einrichtungen/zent...       3      3\n",
       "2  http://klinikum-braunschweig.de/info.php/?id_o...       4      1\n",
       "3  http://klinikum-braunschweig.de/info.php/?id_o...       5      1\n",
       "4  http://klinikum-braunschweig.de/zuweiser/tumor...       6      3"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_instructions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = train_instructions, x = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just wantetd to tak a look at imbalance of target, and as we can see this dataset is a bit unbalanced. This is not a problem, but will have an inpact on the metrics that we will choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_dataset(train_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's inspect this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senologische</th>\n",
       "      <th>brustzentrum</th>\n",
       "      <th>breast</th>\n",
       "      <th>thorax</th>\n",
       "      <th>thorakale</th>\n",
       "      <th>brustkonferenz</th>\n",
       "      <th>rektum</th>\n",
       "      <th>colorec</th>\n",
       "      <th>viszeralchirurgie</th>\n",
       "      <th>visceralonkologischem</th>\n",
       "      <th>...</th>\n",
       "      <th>oral</th>\n",
       "      <th>prätherapeutische</th>\n",
       "      <th>tumore im kindesalter</th>\n",
       "      <th>kinderonkologisches</th>\n",
       "      <th>kinderonkologie</th>\n",
       "      <th>pädiatrische</th>\n",
       "      <th>schwerpunkt</th>\n",
       "      <th>stammzelltransplantation</th>\n",
       "      <th>chirurgisch</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>74.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>44.431151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>112.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       senologische  brustzentrum      breast      thorax  thorakale  \\\n",
       "count         100.0    100.000000  100.000000  100.000000      100.0   \n",
       "mean            0.0      0.001094    0.000290    0.000005        0.0   \n",
       "std             0.0      0.003111    0.002768    0.000051        0.0   \n",
       "min             0.0      0.000000    0.000000    0.000000        0.0   \n",
       "25%             0.0      0.000000    0.000000    0.000000        0.0   \n",
       "50%             0.0      0.000000    0.000000    0.000000        0.0   \n",
       "75%             0.0      0.000000    0.000000    0.000000        0.0   \n",
       "max             0.0      0.019048    0.027664    0.000512        0.0   \n",
       "\n",
       "       brustkonferenz  rektum  colorec  viszeralchirurgie  \\\n",
       "count           100.0   100.0    100.0         100.000000   \n",
       "mean              0.0     0.0      0.0           0.000604   \n",
       "std               0.0     0.0      0.0           0.001859   \n",
       "min               0.0     0.0      0.0           0.000000   \n",
       "25%               0.0     0.0      0.0           0.000000   \n",
       "50%               0.0     0.0      0.0           0.000000   \n",
       "75%               0.0     0.0      0.0           0.000000   \n",
       "max               0.0     0.0      0.0           0.013333   \n",
       "\n",
       "       visceralonkologischem  ...   oral  prätherapeutische  \\\n",
       "count                  100.0  ...  100.0              100.0   \n",
       "mean                     0.0  ...    0.0                0.0   \n",
       "std                      0.0  ...    0.0                0.0   \n",
       "min                      0.0  ...    0.0                0.0   \n",
       "25%                      0.0  ...    0.0                0.0   \n",
       "50%                      0.0  ...    0.0                0.0   \n",
       "75%                      0.0  ...    0.0                0.0   \n",
       "max                      0.0  ...    0.0                0.0   \n",
       "\n",
       "       tumore im kindesalter  kinderonkologisches  kinderonkologie  \\\n",
       "count                  100.0           100.000000            100.0   \n",
       "mean                     0.0             0.000013              0.0   \n",
       "std                      0.0             0.000132              0.0   \n",
       "min                      0.0             0.000000              0.0   \n",
       "25%                      0.0             0.000000              0.0   \n",
       "50%                      0.0             0.000000              0.0   \n",
       "75%                      0.0             0.000000              0.0   \n",
       "max                      0.0             0.001325              0.0   \n",
       "\n",
       "       pädiatrische  schwerpunkt  stammzelltransplantation  chirurgisch  \\\n",
       "count    100.000000   100.000000                100.000000   100.000000   \n",
       "mean       0.000076     0.000303                  0.000027     0.000011   \n",
       "std        0.000639     0.000797                  0.000204     0.000113   \n",
       "min        0.000000     0.000000                  0.000000     0.000000   \n",
       "25%        0.000000     0.000000                  0.000000     0.000000   \n",
       "50%        0.000000     0.000000                  0.000000     0.000000   \n",
       "75%        0.000000     0.000000                  0.000000     0.000000   \n",
       "max        0.006329     0.003759                  0.001890     0.001133   \n",
       "\n",
       "           doc_id  \n",
       "count  100.000000  \n",
       "mean    74.290000  \n",
       "std     44.431151  \n",
       "min      1.000000  \n",
       "25%     32.250000  \n",
       "50%     79.500000  \n",
       "75%    112.500000  \n",
       "max    146.000000  \n",
       "\n",
       "[8 rows x 127 columns]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary columns\n",
    "Columns with only zeros do not provide any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_cols(data):\n",
    "    for column in data.columns:\n",
    "        if data[column].sum() == 0:\n",
    "            data = data.drop(labels=column, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = remove_empty_cols(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is far from perfect extraction of data from websites and It could be done in verious of different methods. But I will show that this approach is sufficient for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let ML begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "I decided to try out two classifiers. RandomForest and Support Vector Classifier. The first one because it's handles well almost any kind of data with generally great resoults and doesn't require much training time. And the second because I believe that distanced based approach could work really well in this case. Let's see how they perform with default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 1, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2,\n",
       "       1, 1, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted = rf.predict(X_test)\n",
    "Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted = clf.predict(X_test)\n",
    "Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "As we can see even though score isn't terrible '0.63', this classifier with default settings is unusable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Couple of steps ago I mentioned that this dataset is inbalanced. This is important information because some scoring techniques are not made to handle unbalanced datastes, thus they can be misleading. I will use one main scoring method for hyperparameter tuning and 2 support metrics, just to make sure we improved our classifier. \n",
    "\n",
    "Multiclass clasiffication on unbalanced dataset discouraged me from using my typical ROC AUC, or Weighted TPR-TNR, but Cohen's Kappa and MCC should perform great in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen’s Kappa\n",
    "This is my main matric that I will be using in `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4736842105263158"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(Y_test, Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathews Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47810549759985493"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(Y_test,Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5122807017543859"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(Y_test, Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classifier(classifier, Y_test):\n",
    "    Y_predicted = classifier.predict(X_test)\n",
    "    print(Y_predicted)\n",
    "    \n",
    "    CK = cohen_kappa_score(Y_test, Y_predicted)\n",
    "    MCC = matthews_corrcoef(Y_test, Y_predicted)\n",
    "    BA = balanced_accuracy_score(Y_test, Y_predicted)\n",
    "    \n",
    "    print(f\"Cohen's Kappa : {CK}\")\n",
    "    print(f\"Matthews Corr : {MCC}\")\n",
    "    print(f\"Balanced Acc  : {BA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa : 0.5419847328244276\n",
      "Matthews Corr : 0.5671717776884524\n",
      "Balanced Acc  : 0.5157894736842105\n"
     ]
    }
   ],
   "source": [
    "score_classifier(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubles with feature engineering\n",
    "One of the first things that I wanted to do was to scale this dataset, but I was trying a few diffrent scalers with negative result, so I decided not to use them.\n",
    "Sadly same goes with standarization and normalization.\n",
    "This is somewhat expected because my dataset is a sparse martix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.110223e-18</td>\n",
       "      <td>8.021361e-17</td>\n",
       "      <td>1.249001e-17</td>\n",
       "      <td>2.886580e-17</td>\n",
       "      <td>-2.248202e-17</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>7.771561e-17</td>\n",
       "      <td>8.326673e-19</td>\n",
       "      <td>-3.552714e-17</td>\n",
       "      <td>2.275957e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>5.551115e-18</td>\n",
       "      <td>1.021405e-16</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>4.996004e-18</td>\n",
       "      <td>2.248202e-17</td>\n",
       "      <td>-2.026157e-17</td>\n",
       "      <td>6.661338e-17</td>\n",
       "      <td>-4.996004e-18</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>-1.376677e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.657828e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-9.509497e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>1.178508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.795665e-02</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>8.643147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.800329e+00</td>\n",
       "      <td>9.938471e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>6.883377e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.090616e+00</td>\n",
       "      <td>9.700623e+00</td>\n",
       "      <td>5.563348e+00</td>\n",
       "      <td>8.905978e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.967837e+00</td>\n",
       "      <td>5.697854e+00</td>\n",
       "      <td>9.685380e+00</td>\n",
       "      <td>8.203259e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.830653e+00</td>\n",
       "      <td>4.359889e+00</td>\n",
       "      <td>9.158684e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>1.622089e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   1.110223e-18  8.021361e-17  1.249001e-17  2.886580e-17 -2.248202e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "25%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "50%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "75%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "max    5.800329e+00  9.938471e+00  9.949874e+00  6.883377e+00  9.949874e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   2.303713e-17  7.771561e-17  8.326673e-19 -3.552714e-17  2.275957e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "25%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "50%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "75%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "max    9.949874e+00  9.090616e+00  9.700623e+00  5.563348e+00  8.905978e+00   \n",
       "\n",
       "       ...            56            57            58            59  \\\n",
       "count  ...  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   ...  5.551115e-18  1.021405e-16  2.303713e-17  4.996004e-18   \n",
       "std    ...  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "25%    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "50%    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "75%    ... -7.795665e-02 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "max    ...  4.967837e+00  5.697854e+00  9.685380e+00  8.203259e+00   \n",
       "\n",
       "                 60            61            62            63            64  \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   2.248202e-17 -2.026157e-17  6.661338e-17 -4.996004e-18  2.303713e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "25%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "50%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "75%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "max    9.949874e+00  9.830653e+00  4.359889e+00  9.158684e+00  9.949874e+00   \n",
       "\n",
       "                 65  \n",
       "count  1.000000e+02  \n",
       "mean  -1.376677e-16  \n",
       "std    1.005038e+00  \n",
       "min   -1.657828e+00  \n",
       "25%   -9.509497e-01  \n",
       "50%    1.178508e-01  \n",
       "75%    8.643147e-01  \n",
       "max    1.622089e+00  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FE(X,y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size = 0.3, random_state=0)\n",
    "    classifier = RandomForestClassifier(random_state=0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    score_classifier(classifier,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Cohen's Kappa : 0.0\n",
      "Matthews Corr : 0.0\n",
      "Balanced Acc  : 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "test_FE(X_t, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.110223e-18</td>\n",
       "      <td>8.021361e-17</td>\n",
       "      <td>1.249001e-17</td>\n",
       "      <td>2.886580e-17</td>\n",
       "      <td>-2.248202e-17</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>7.771561e-17</td>\n",
       "      <td>8.326673e-19</td>\n",
       "      <td>-3.552714e-17</td>\n",
       "      <td>2.275957e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>5.551115e-18</td>\n",
       "      <td>1.021405e-16</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>4.996004e-18</td>\n",
       "      <td>2.248202e-17</td>\n",
       "      <td>-2.026157e-17</td>\n",
       "      <td>6.661338e-17</td>\n",
       "      <td>-4.996004e-18</td>\n",
       "      <td>2.303713e-17</td>\n",
       "      <td>-1.376677e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.657828e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-9.509497e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.852845e-01</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>1.178508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.536057e-01</td>\n",
       "      <td>-1.052477e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-3.263719e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.542422e-01</td>\n",
       "      <td>-1.205678e-01</td>\n",
       "      <td>-2.758943e-01</td>\n",
       "      <td>-1.606338e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.795665e-02</td>\n",
       "      <td>-2.089183e-01</td>\n",
       "      <td>-1.210851e-01</td>\n",
       "      <td>-1.463253e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>-1.195948e-01</td>\n",
       "      <td>-3.822609e-01</td>\n",
       "      <td>-1.321860e-01</td>\n",
       "      <td>-1.005038e-01</td>\n",
       "      <td>8.643147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.800329e+00</td>\n",
       "      <td>9.938471e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>6.883377e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.090616e+00</td>\n",
       "      <td>9.700623e+00</td>\n",
       "      <td>5.563348e+00</td>\n",
       "      <td>8.905978e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.967837e+00</td>\n",
       "      <td>5.697854e+00</td>\n",
       "      <td>9.685380e+00</td>\n",
       "      <td>8.203259e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>9.830653e+00</td>\n",
       "      <td>4.359889e+00</td>\n",
       "      <td>9.158684e+00</td>\n",
       "      <td>9.949874e+00</td>\n",
       "      <td>1.622089e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   1.110223e-18  8.021361e-17  1.249001e-17  2.886580e-17 -2.248202e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "25%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "50%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "75%   -3.536057e-01 -1.052477e-01 -1.005038e-01 -3.263719e-01 -1.005038e-01   \n",
       "max    5.800329e+00  9.938471e+00  9.949874e+00  6.883377e+00  9.949874e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   2.303713e-17  7.771561e-17  8.326673e-19 -3.552714e-17  2.275957e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "25%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "50%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "75%   -1.005038e-01 -1.542422e-01 -1.205678e-01 -2.758943e-01 -1.606338e-01   \n",
       "max    9.949874e+00  9.090616e+00  9.700623e+00  5.563348e+00  8.905978e+00   \n",
       "\n",
       "       ...            56            57            58            59  \\\n",
       "count  ...  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   ...  5.551115e-18  1.021405e-16  2.303713e-17  4.996004e-18   \n",
       "std    ...  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "25%    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "50%    ... -4.852845e-01 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "75%    ... -7.795665e-02 -2.089183e-01 -1.210851e-01 -1.463253e-01   \n",
       "max    ...  4.967837e+00  5.697854e+00  9.685380e+00  8.203259e+00   \n",
       "\n",
       "                 60            61            62            63            64  \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   2.248202e-17 -2.026157e-17  6.661338e-17 -4.996004e-18  2.303713e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "25%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "50%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "75%   -1.005038e-01 -1.195948e-01 -3.822609e-01 -1.321860e-01 -1.005038e-01   \n",
       "max    9.949874e+00  9.830653e+00  4.359889e+00  9.158684e+00  9.949874e+00   \n",
       "\n",
       "                 65  \n",
       "count  1.000000e+02  \n",
       "mean  -1.376677e-16  \n",
       "std    1.005038e+00  \n",
       "min   -1.657828e+00  \n",
       "25%   -9.509497e-01  \n",
       "50%    1.178508e-01  \n",
       "75%    8.643147e-01  \n",
       "max    1.622089e+00  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_t = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Cohen's Kappa : 0.0\n",
      "Matthews Corr : 0.0\n",
      "Balanced Acc  : 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "test_FE(X_t,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.969230e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>7.133929e-08</td>\n",
       "      <td>8.092857e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.205348e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.665597e-07</td>\n",
       "      <td>6.204219e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.352041e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2.767741e-07</td>\n",
       "      <td>8.092857e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.969230e-06</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>7.133929e-07</td>\n",
       "      <td>8.092857e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.610395e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>3.093994e-06</td>\n",
       "      <td>5.278386e-06</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1.352041e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>2.167872e-06</td>\n",
       "      <td>8.092857e-06</td>\n",
       "      <td>4.871572e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>1.969230e-05</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>7.133929e-06</td>\n",
       "      <td>8.092857e-05</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>2.527778e-05</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>2.054348e-05</td>\n",
       "      <td>5.190351e-05</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>1.352041e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>2.054348e-05</td>\n",
       "      <td>8.092857e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1             2           3             4   \\\n",
       "count  100.000000  100.000000  1.000000e+02  100.000000  1.000000e+02   \n",
       "mean     0.000065    0.000011  1.969230e-07    0.000037  7.133929e-08   \n",
       "std      0.000200    0.000106  1.969230e-06    0.000252  7.133929e-07   \n",
       "min      0.000000    0.000000  0.000000e+00    0.000000  0.000000e+00   \n",
       "25%      0.000000    0.000000  0.000000e+00    0.000000  0.000000e+00   \n",
       "50%      0.000000    0.000000  0.000000e+00    0.000000  0.000000e+00   \n",
       "75%      0.000000    0.000000  0.000000e+00    0.000000  0.000000e+00   \n",
       "max      0.001248    0.001064  1.969230e-05    0.002497  7.133929e-06   \n",
       "\n",
       "                 5           6             7           8           9   ...  \\\n",
       "count  1.000000e+02  100.000000  1.000000e+02  100.000000  100.000000  ...   \n",
       "mean   8.092857e-07    0.000002  3.205348e-07    0.000009    0.000005  ...   \n",
       "std    8.092857e-06    0.000010  2.610395e-06    0.000040    0.000030  ...   \n",
       "min    0.000000e+00    0.000000  0.000000e+00    0.000000    0.000000  ...   \n",
       "25%    0.000000e+00    0.000000  0.000000e+00    0.000000    0.000000  ...   \n",
       "50%    0.000000e+00    0.000000  0.000000e+00    0.000000    0.000000  ...   \n",
       "75%    0.000000e+00    0.000000  0.000000e+00    0.000000    0.000000  ...   \n",
       "max    8.092857e-05    0.000092  2.527778e-05    0.000332    0.000261  ...   \n",
       "\n",
       "               56            57            58          59            60  \\\n",
       "count  100.000000  1.000000e+02  1.000000e+02  100.000000  1.000000e+02   \n",
       "mean     0.000012  6.665597e-07  6.204219e-07    0.000013  1.352041e-07   \n",
       "std      0.000027  3.093994e-06  5.278386e-06    0.000093  1.352041e-06   \n",
       "min      0.000000  0.000000e+00  0.000000e+00    0.000000  0.000000e+00   \n",
       "25%      0.000000  0.000000e+00  0.000000e+00    0.000000  0.000000e+00   \n",
       "50%      0.000000  0.000000e+00  0.000000e+00    0.000000  0.000000e+00   \n",
       "75%      0.000006  0.000000e+00  0.000000e+00    0.000000  0.000000e+00   \n",
       "max      0.000121  2.054348e-05  5.190351e-05    0.000754  1.352041e-05   \n",
       "\n",
       "               61          62            63            64            65  \n",
       "count  100.000000  100.000000  1.000000e+02  1.000000e+02  1.000000e+02  \n",
       "mean     0.000001    0.000012  2.767741e-07  8.092857e-07  9.999999e-01  \n",
       "std      0.000011    0.000041  2.167872e-06  8.092857e-06  4.871572e-07  \n",
       "min      0.000000    0.000000  0.000000e+00  0.000000e+00  9.999953e-01  \n",
       "25%      0.000000    0.000000  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "50%      0.000000    0.000000  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "75%      0.000000    0.000000  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "max      0.000111    0.000318  2.054348e-05  8.092857e-05  1.000000e+00  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Normalizer().fit(X)\n",
    "X_t = pd.DataFrame(transformer.transform(X))\n",
    "X_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now is the time to improve our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using `RandomizedSearchCV` because this algorith is fast and provides results very close to grid serach, which generally is too time consuming to use. I have to provide it with classifier, scoring function and parameters grid. The outcome of this function should be close to best possible model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(cohen_kappa_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    \"n_estimators\": [50,100],\n",
    "    \"criterion\": [\"gini\",\"entropy\"],\n",
    "    \"max_depth\" : range(2,15,2),\n",
    "    \"min_samples_split\": range(1,6),\n",
    "    \"min_samples_leaf\": range(1,4),\n",
    "    \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "random=GridSearchCV(estimator=classifier, param_grid=params, scoring=my_scorer, cv=6, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 1260 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-714-dc9461d4c2df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bartek\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_result = random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_result.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 50,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa : -0.18226600985221664\n",
      "Matthews Corr : -0.24258948651406492\n",
      "Balanced Acc  : 0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "score_classifier(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Areas for improvement\n",
    "Those are just a few notes I want to leave at the end of this task. I chose a specific, possibly not the best approach, but I'm quite happy with the result. Nevertheless there is always room for improvement. \n",
    "\n",
    "\n",
    "\n",
    "### Filter website data more efficient\n",
    "    At the begining I made impactful decision to remove some parts of html i.e. footer, nav. This helped me to reduce amount of words that have nothing to do with the topic but I would want to see if simply removing non german words and html tags wouldn't have worked better. \n",
    "\n",
    "### Experiment with feature engineering\n",
    "    Dataset I created was rather specific and most common feature engineering techniques couldn'd even be used on it. But one could collect data defferently, maybe in a more complex way including number of names on site, analizing the complexity of the language used, categorizing the url. These would take extra time to explore and extract, but this has potential of improving the predictions by a great amount. \n",
    "\n",
    "### Different models\n",
    "    NPL can be done in many ways, but It propably shines with deep learning. From my expirience this approach is much more time consuming and I didn't want to risk it, since this task is time limited and my laptop isn't the fastest. But If I had to do this task again, this is propably what I would use. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
